{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'baselines'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4cb2f6301fa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeep_rl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/LiNCLAB/State representation in RL/DeepRL-master/deep_rl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcomponent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/LiNCLAB/State representation in RL/DeepRL-master/deep_rl/agent/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mDQN_agent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mDQN_agent_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mDSR_agent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mDSR_agent_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mavDSR_agent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/LiNCLAB/State representation in RL/DeepRL-master/deep_rl/agent/DQN_agent.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#######################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/LiNCLAB/State representation in RL/DeepRL-master/deep_rl/network/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnetwork_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnetwork_bodies\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnetwork_heads\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/LiNCLAB/State representation in RL/DeepRL-master/deep_rl/network/network_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/LiNCLAB/State representation in RL/DeepRL-master/deep_rl/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnormalizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlotter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/LiNCLAB/State representation in RL/DeepRL-master/deep_rl/utils/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# declaration at the top                                              #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#######################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnormalizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/LiNCLAB/State representation in RL/DeepRL-master/deep_rl/utils/normalizer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbaselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean_std\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRunningMeanStd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'baselines'"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "sys.path.append('../')\n",
    "from deep_rl import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import trange, tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "!mkdir log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "sys.path.append('')\n",
    "from deep_rl import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import trange, tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "from deep_rl.component.fourrooms_collect import *\n",
    "from deep_rl.component.fourrooms import *\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = 'open'\n",
    "\n",
    "if layout == '3rooms' or layout == '3roomsh':\n",
    "    cell_num = 101\n",
    "    max_step_dqn = 1e5\n",
    "    linear_schedule_dqn = 6e4\n",
    "elif layout == 'maze':\n",
    "    cell_num = 75\n",
    "    max_step_dqn = 1.5e5\n",
    "    linear_schedule_dqn = 9e4\n",
    "else:\n",
    "    cell_num = 104\n",
    "    max_step_dqn = 7e4\n",
    "    linear_schedule_dqn = 4e4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 13, 13])\n",
      "torch.Size([1, 16, 11, 11]) after conv1\n",
      "torch.Size([1, 32, 9, 9]) after conv2\n",
      "torch.Size([1, 32, 4, 4]) after pooling\n",
      "torch.Size([1, 512]) after flatten\n"
     ]
    }
   ],
   "source": [
    "t = torch.zeros([1, 4, 13, 13])\n",
    "\n",
    "conv1 = nn.Conv2d(4, 16, 3, 1)\n",
    "\n",
    "conv2 = nn.Conv2d(16, 32, 3, 1)\n",
    "\n",
    "pool = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "print(t.shape)\n",
    "\n",
    "t = conv1(t)\n",
    "print(t.shape, 'after conv1')\n",
    "\n",
    "t = conv2(t)\n",
    "print(t.shape, 'after conv2')\n",
    "\n",
    "t = F.max_pool2d(t, kernel_size=2)\n",
    "print(t.shape, 'after pooling')\n",
    "\n",
    "t = torch.flatten(t, 1)\n",
    "print(t.shape, 'after flatten')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "dims = 32 * ((13 - (3-1)*2) // 2) ** 2\n",
    "\n",
    "print(dims)\n",
    "# layers = nn.ModuleList(\n",
    "#     [layer_init(nn.Linear(dim_in, dim_out)) for dim_in, dim_out in zip(dims[:-1], dims[1:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from .network_utils import *\n",
    "# from .network_bodies import *\n",
    "# from torch.nn.parameter import Parameter\n",
    "\n",
    "class DQNCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Added by Surya.\n",
    "    SR fully connected body network.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_dim, body=None, hidden_units=(), gate=F.relu, config=1):\n",
    "        \"\"\"\n",
    "        config -> type of learning on top of state abstraction\n",
    "            0 - typical SR with weights sharing\n",
    "            1 - learning SR without weights sharing\n",
    "        \"\"\"\n",
    "        super(DQNCNN, self).__init__()\n",
    "        self.body = body\n",
    "        self.output_dim = output_dim\n",
    "        # width 是 observation的边长\n",
    "        self.width = 13\n",
    "\n",
    "        # CNN layers\n",
    "        # Conv2d 的参数 （输入channel， 输出channel，kernel size， kernel位移/stride）\n",
    "        self.conv1 = nn.Conv2d(4, 64, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, 1)\n",
    "        self.fc_size = 128 * ((self.width - (3-1)*4) // 2) ** 2\n",
    "        \n",
    "        self.fc = nn.Linear(2048, 4)\n",
    "        \n",
    "        self.gate = gate\n",
    "\n",
    "    def forward(self, x):\n",
    "        phi = torch.Tensor(x)\n",
    "#         print(phi.shape, 'original shape')\n",
    "#         if self.body is not None:\n",
    "#             phi = self.body(tensor(x)) # shape: b x state_dim\n",
    "            \n",
    "        psi = phi\n",
    "        \n",
    "#         print(psi.shape, 'after body shape')\n",
    "\n",
    "        # Convert to image\n",
    "        psi = psi.view(phi.size(0), 4, self.width, self.width)\n",
    "\n",
    "        # Conv layers\n",
    "        psi = self.conv1(psi)\n",
    "#         print(psi.shape, 'after conv1')\n",
    "        psi = F.relu(psi)\n",
    "        psi = self.conv2(psi)\n",
    "#         print(psi.shape, 'after conv2')\n",
    "        psi = F.relu(psi)\n",
    "        psi = F.max_pool2d(psi, 2)\n",
    "        \n",
    "#         print(psi.shape, 'after pooling')\n",
    "        \n",
    "        psi = torch.flatten(psi, 1)\n",
    "\n",
    "        # FC layers\n",
    "        psi = self.fc(psi)\n",
    "        \n",
    "        return psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_dqn = 2e-3 #from 0.05 - 0.001\n",
    "max_step_dqn = 1e5\n",
    "linear_schedule_dqn = 6e4\n",
    "\n",
    "def dqn_feature(**kwargs):\n",
    "    generate_tag(kwargs)\n",
    "    kwargs.setdefault('log_level', 0)\n",
    "    config = Config()\n",
    "    config.DEVICE = torch.device('cpu')\n",
    "    config.merge(kwargs)\n",
    "\n",
    "    config.task_fn = lambda: Task(config.game)\n",
    "    config.eval_env = config.task_fn()\n",
    "\n",
    "    config.optimizer_fn = lambda params: torch.optim.RMSprop(params, learning_rate_dqn)\n",
    "    config.network_fn = lambda: DQNCNN(config.action_dim, SRIdentityBody(config.state_dim), \\\n",
    "                                      hidden_units=(2000,))\n",
    "#     config.network_fn = lambda: VanillaNet(config.action_dim, FCBody(config.state_dim, hidden_units=(16,)))\n",
    "    config.replay_fn = lambda: AsyncReplay(memory_size=int(1e5), batch_size=10)\n",
    "\n",
    "    config.random_action_prob = LinearSchedule(1.0, 0.1, linear_schedule_dqn)\n",
    "    config.discount = 0.9\n",
    "    config.target_network_update_freq = 200\n",
    "    config.exploration_steps = 0\n",
    "    # config.double_q = True\n",
    "    config.double_q = False\n",
    "    config.sgd_update_frequency = 4\n",
    "    config.gradient_clip = 5\n",
    "    config.eval_interval = int(5e3)\n",
    "    config.max_steps = max_step_dqn\n",
    "    config.async_actor = False\n",
    "    agent = DQNAgent(config)\n",
    "\n",
    "    #run_steps function below\n",
    "    config = agent.config\n",
    "    agent_name = agent.__class__.__name__\n",
    "    t0 = time.time()\n",
    "    # agent.step()\n",
    "    # plt.figure(figsize=(10,4))\n",
    "    while True:\n",
    "        # print(agent.actor._task.env.envs[0].goal)\n",
    "        if config.save_interval and not agent.total_steps % config.save_interval:\n",
    "            agent.save('data/%s-%s-%d' % (agent_name, config.tag, agent.total_steps))\n",
    "        if config.log_interval and not agent.total_steps % config.log_interval:\n",
    "            t0 = time.time()\n",
    "        if config.eval_interval and not agent.total_steps % config.eval_interval:\n",
    "            agent.eval_episodes()\n",
    "            pass\n",
    "        if config.max_steps and agent.total_steps >= config.max_steps:\n",
    "            return agent\n",
    "            break\n",
    "        agent.step()\n",
    "        # plt.title('step: {}'.format(agent.total_steps), fontsize=20)\n",
    "        # plt.imshow(agent.actor._task.env.envs[0].render(), cmap='Blues', )\n",
    "        agent.switch_task()\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-12 19:50:37,050 - root - INFO: steps 0, episodic_return_test 0.30(0.14)\n",
      "2021-04-12 19:50:56,381 - root - INFO: steps 5000, episodic_return_test 0.60(0.38)\n",
      "2021-04-12 19:51:11,447 - root - INFO: steps 10000, episodic_return_test 0.90(0.30)\n",
      "2021-04-12 19:51:27,611 - root - INFO: steps 15000, episodic_return_test 3.20(0.54)\n",
      "2021-04-12 19:51:42,902 - root - INFO: steps 20000, episodic_return_test 1.90(0.50)\n",
      "2021-04-12 19:51:58,037 - root - INFO: steps 25000, episodic_return_test 3.80(0.91)\n",
      "2021-04-12 19:52:13,088 - root - INFO: steps 30000, episodic_return_test 3.10(0.89)\n",
      "2021-04-12 19:52:28,578 - root - INFO: steps 35000, episodic_return_test 3.60(0.91)\n",
      "2021-04-12 19:52:44,446 - root - INFO: steps 40000, episodic_return_test 4.50(0.76)\n",
      "2021-04-12 19:52:59,512 - root - INFO: steps 45000, episodic_return_test 5.90(0.81)\n",
      "2021-04-12 19:53:14,485 - root - INFO: steps 50000, episodic_return_test 5.00(0.97)\n",
      "2021-04-12 19:53:29,591 - root - INFO: steps 55000, episodic_return_test 5.00(0.93)\n",
      "2021-04-12 19:53:45,486 - root - INFO: steps 60000, episodic_return_test 6.00(0.89)\n",
      "2021-04-12 19:54:01,336 - root - INFO: steps 65000, episodic_return_test 6.20(0.86)\n",
      "2021-04-12 19:54:16,701 - root - INFO: steps 70000, episodic_return_test 7.30(0.60)\n",
      "2021-04-12 19:54:31,128 - root - INFO: steps 75000, episodic_return_test 5.70(0.81)\n",
      "2021-04-12 19:54:46,121 - root - INFO: steps 80000, episodic_return_test 8.00(0.55)\n",
      "2021-04-12 19:55:01,030 - root - INFO: steps 85000, episodic_return_test 6.00(1.17)\n",
      "2021-04-12 19:55:16,320 - root - INFO: steps 90000, episodic_return_test 5.30(0.79)\n",
      "2021-04-12 19:55:31,295 - root - INFO: steps 95000, episodic_return_test 6.50(1.12)\n",
      "2021-04-12 19:55:46,882 - root - INFO: steps 100000, episodic_return_test 6.40(0.99)\n"
     ]
    }
   ],
   "source": [
    "dqn = dqn_feature(game='FourRoomsCollect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 13, 13)\n"
     ]
    }
   ],
   "source": [
    "env = ClctFourRooms(config=2)\n",
    "\n",
    "env.reset()\n",
    "\n",
    "print(env.observation().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb45f29f2b0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = FourRoomsMatrix(layout='3roomsh')\n",
    "\n",
    "print(len(env.init_states))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.imshow(env.reset().reshape([13, 13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 13, 13]) original shape\n",
      "torch.Size([1, 4, 13, 13]) after body shape\n",
      "torch.Size([1, 64, 11, 11]) after conv1\n",
      "torch.Size([1, 128, 9, 9]) after conv2\n",
      "torch.Size([1, 128, 4, 4]) after pooling\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0353, -0.0005,  0.0056, -0.0159]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = Task('FourRoomsCollect')\n",
    "# task.state_dim\n",
    "cnn = DQNCNN(4, None, hidden_units=(2000,))\n",
    "\n",
    "cnn([env.observation()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 113, 70, 75, 47, 117, 80, 34, 71, 11]\n",
      "[58, 113, 70, 75, 47, 117, 80, 34, 71, 11]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f812468cb20>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = ClctFourRooms()\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(env.render())\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(env.render())\n",
    "\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRNetCNN_MultiChannel(nn.Module):\n",
    "    \"\"\"\n",
    "    Added by Surya.\n",
    "    SR fully connected body network.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_dim, body, hidden_units=(3000,), gate=F.relu, config=0):\n",
    "        \"\"\"\n",
    "        config -> type of learning on top of state abstraction\n",
    "            0 - typical SR with weights sharing\n",
    "            1 - learning SR without weights sharing\n",
    "        \"\"\"\n",
    "        super(SRNetCNN_MultiChannel, self).__init__()\n",
    "        self.body = body\n",
    "        self.output_dim = output_dim\n",
    "        self.width = 13\n",
    "        self.init_channels = int(self.body.feature_dim / np.square(self.width))\n",
    "\n",
    "        \n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv2d(self.init_channels, 64, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, 1)\n",
    "#         self.conv3 = nn.Conv2d(64, 128, 3, 1)\n",
    "        \n",
    "        self.fc_size = 128 * ((self.width - (3-1)*2) // 2) ** 2\n",
    "\n",
    "#         # FC layers\n",
    "#         dims = (self.fc_size,) + hidden_units + (body.feature_dim * output_dim,)\n",
    "# #         print(self.fc_size, hidden_units, body.feature_dim, output_dim)\n",
    "# #         print(dims)\n",
    "#         self.layers = nn.ModuleList(\n",
    "#             [layer_init(nn.Linear(dim_in, dim_out)) for dim_in, dim_out in zip(dims[:-1], dims[1:])])\n",
    "    \n",
    "#         print(self.layers)\n",
    "\n",
    "        self.fc = nn.Linear(self.fc_size, int(self.body.feature_dim * output_dim / self.init_channels))\n",
    "        \n",
    "        self.gate = gate\n",
    "        self.feature_dim = body.feature_dim * output_dim\n",
    "        if(config == 0):\n",
    "            self.psi2q = Psi2QNet(output_dim, 169)\n",
    "        if(config == 1):\n",
    "            self.psi2q = Psi2QNetFC(output_dim, 169)\n",
    "        self.to(Config.DEVICE)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(x.shape, 'original shape')\n",
    "        phi = self.body(tensor(x)) # shape: b x state_dim\n",
    "#         print(phi.shape)\n",
    "#         print(phi.shape)\n",
    "        psi = phi\n",
    "        \n",
    "#         print(psi.shape, 'after body shape')\n",
    "\n",
    "        # Convert to image\n",
    "        psi = psi.view(phi.size(0), 4, self.width, self.width)\n",
    "\n",
    "        # Conv layers\n",
    "        psi = self.conv1(psi)\n",
    "#         print(psi.shape, 'after conv1')\n",
    "        psi = F.relu(psi)\n",
    "        psi = self.conv2(psi)\n",
    "#         print(psi.shape, 'after conv2')\n",
    "        psi = F.relu(psi)\n",
    "        psi = F.max_pool2d(psi, 2)\n",
    "        \n",
    "#         print(psi.shape, 'after pooling')\n",
    "        \n",
    "        psi = torch.flatten(psi, 1)\n",
    "\n",
    "        # FC layers\n",
    "#         for layer in self.layers[:-1]:\n",
    "#             psi = self.gate(layer(psi))\n",
    "#         psi = self.layers[-1](psi)\n",
    "        psi = self.fc(psi)\n",
    "        \n",
    "#         print(f'debug : {psi.shape}, {psi.size(0)}, {self.output_dim}, {self.body.feature_dim}')\n",
    "        \n",
    "        psi = psi.view(psi.size(0), self.output_dim, 169) # shape: b x action_dim x state_dim\n",
    "        \n",
    "#         print(f'after view shape : {psi.shape}')\n",
    "        out = self.psi2q(psi)\n",
    "        phi = phi[:, 1, :, :]\n",
    "\n",
    "        return phi, psi, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRNetCNN_MultiChannel(\n",
      "  (body): SRIdentityBody()\n",
      "  (conv1): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=676, bias=True)\n",
      "  (psi2q): Psi2QNet()\n",
      ")\n",
      "torch.Size([10, 13, 13])\n",
      "torch.Size([10, 4, 169])\n",
      "torch.Size([10, 4])\n"
     ]
    }
   ],
   "source": [
    "task = Task('FourRoomsCollectNoTerm')\n",
    "\n",
    "cnn = SRNetCNN_MultiChannel(4, SRIdentityBody(task.state_dim), \\\n",
    "                                      hidden_units=(2000,), config=0)\n",
    "\n",
    "ipt = np.zeros([10, 4, 13, 13])\n",
    "\n",
    "a, b, c = cnn(ipt)\n",
    "print(cnn)\n",
    "\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsr_feature_init(ref,**kwargs):\n",
    "    generate_tag(kwargs)\n",
    "    kwargs.setdefault('log_level', 0)\n",
    "    config = Config()\n",
    "    config.async_actor = False\n",
    "    config.DEVICE = torch.device('0')\n",
    "\n",
    "    config.merge(kwargs)\n",
    "\n",
    "    config.task_fn = lambda: Task(config.game)\n",
    "    config.eval_env = config.task_fn()\n",
    "    config.c = 1\n",
    "\n",
    "    config.optimizer_fn = lambda params: torch.optim.RMSprop(params, 0.002)\n",
    "#     config.network_fn = lambda: SRNetCNN(config.action_dim, SRIdentityBody(config.state_dim), \\\n",
    "#                                       hidden_units=(2000,), config=config.style) #CHECK\n",
    "\n",
    "    config.network_fn = lambda: SRNet(config.action_dim, SRIdentityBody(config.state_dim), \\\n",
    "                                      hidden_units=(2000,), config=config.style) #CHECK\n",
    "    config.replay_fn = lambda: AsyncReplay(memory_size=int(1e5), batch_size=10)\n",
    "\n",
    "    config.random_action_prob = LinearSchedule(1.0, 0.1, linear_schedule_dqn)\n",
    "    config.discount = 0.99\n",
    "    config.target_network_update_freq = 200\n",
    "    config.exploration_steps = 0\n",
    "    # config.double_q = True\n",
    "    config.double_q = False\n",
    "    config.sgd_update_frequency = 4\n",
    "    config.gradient_clip = 5\n",
    "    config.eval_interval = int(5e3)\n",
    "    config.max_steps = max_step_dqn\n",
    "    config.async_actor = False\n",
    "    \n",
    "    agent = DSRAgent(config)\n",
    "    #run_steps function below\n",
    "    config = agent.config\n",
    "    agent_name = agent.__class__.__name__\n",
    "    if(ref is not None):\n",
    "        print(agent.network.load_state_dict(ref.network.state_dict(), strict=False))\n",
    "    t0 = time.time()\n",
    "    while True:\n",
    "        if config.save_interval and not agent.total_steps % config.save_interval:\n",
    "            agent.save('data/%s-%s-%d' % (agent_name, config.tag, agent.total_steps))\n",
    "        if config.log_interval and not agent.total_steps % config.log_interval:\n",
    "#             agent.logger.info('steps %d, %.2f steps/s' % (agent.total_steps, config.log_interval / (time.time() - t0)))\n",
    "            t0 = time.time()\n",
    "        if config.eval_interval and not agent.total_steps % config.eval_interval:\n",
    "            agent.eval_episodes()\n",
    "        if config.max_steps and agent.total_steps >= config.max_steps:\n",
    "            return agent\n",
    "            break\n",
    "#         import pdb; pdb.set_trace()\n",
    "        agent.step()\n",
    "        agent.switch_task()\n",
    "        \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'deep_rl.network.network_heads.SRNet'>\n",
      "<class 'deep_rl.network.network_heads.SRNet'>\n",
      "<class 'deep_rl.network.network_heads.SRNet'>\n",
      "<class 'deep_rl.network.network_heads.SRNet'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-13 15:26:21,749 - root - INFO: steps 0, episodic_return_test -200.00(0.00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for one step: 5.1883 seconds\n",
      "time for one step: 0.0079 seconds\n",
      "time for one step: 0.0074 seconds\n",
      "time for one step: 0.0075 seconds\n",
      "time for one step: 0.0072 seconds\n",
      "time for one step: 0.0070 seconds\n",
      "time for one step: 0.0068 seconds\n",
      "time for one step: 0.0073 seconds\n",
      "time for one step: 0.0071 seconds\n",
      "time for one step: 0.0068 seconds\n",
      "time for one step: 0.0071 seconds\n",
      "time for one step: 0.0071 seconds\n",
      "time for one step: 0.0074 seconds\n",
      "time for one step: 0.0073 seconds\n",
      "time for one step: 0.0070 seconds\n",
      "time for one step: 0.0070 seconds\n",
      "time for one step: 0.0071 seconds\n",
      "time for one step: 0.0070 seconds\n",
      "time for one step: 0.0068 seconds\n",
      "time for one step: 0.0075 seconds\n",
      "time for one step: 0.0068 seconds\n",
      "time for one step: 0.0071 seconds\n",
      "time for one step: 0.0066 seconds\n",
      "time for one step: 0.0073 seconds\n",
      "time for one step: 0.0077 seconds\n",
      "time for one step: 0.0077 seconds\n",
      "time for one step: 0.0089 seconds\n",
      "time for one step: 0.0097 seconds\n",
      "time for one step: 0.0113 seconds\n",
      "time for one step: 0.0096 seconds\n",
      "time for one step: 0.0093 seconds\n",
      "time for one step: 0.0090 seconds\n",
      "time for one step: 0.0081 seconds\n",
      "time for one step: 0.0080 seconds\n",
      "time for one step: 0.0068 seconds\n",
      "time for one step: 0.0070 seconds\n",
      "time for one step: 0.0074 seconds\n",
      "time for one step: 0.0074 seconds\n",
      "time for one step: 0.0074 seconds\n",
      "time for one step: 0.0074 seconds\n",
      "time for one step: 0.0073 seconds\n",
      "time for one step: 0.0075 seconds\n",
      "time for one step: 0.0078 seconds\n",
      "time for one step: 0.0073 seconds\n",
      "time for one step: 0.0077 seconds\n",
      "time for one step: 0.0079 seconds\n",
      "time for one step: 0.0077 seconds\n",
      "time for one step: 0.0091 seconds\n",
      "time for one step: 0.0079 seconds\n",
      "time for one step: 0.0075 seconds\n",
      "time for one step: 0.0075 seconds\n",
      "time for one step: 0.0075 seconds\n",
      "time for one step: 0.0075 seconds\n",
      "time for one step: 0.0072 seconds\n",
      "time for one step: 0.0074 seconds\n",
      "time for one step: 0.0074 seconds\n",
      "time for one step: 0.0072 seconds\n",
      "time for one step: 0.0076 seconds\n",
      "time for one step: 0.0073 seconds\n",
      "time for one step: 0.0073 seconds\n",
      "time for one step: 0.0078 seconds\n",
      "time for one step: 0.0072 seconds\n",
      "time for one step: 0.0082 seconds\n",
      "time for one step: 0.0074 seconds\n",
      "time for one step: 0.0079 seconds\n",
      "time for one step: 0.0076 seconds\n",
      "time for one step: 0.0083 seconds\n",
      "time for one step: 0.0073 seconds\n",
      "time for one step: 0.0076 seconds\n",
      "time for one step: 0.0070 seconds\n",
      "time for one step: 0.0075 seconds\n",
      "time for one step: 0.0077 seconds\n",
      "time for one step: 0.0073 seconds\n",
      "time for one step: 0.0073 seconds\n",
      "time for one step: 0.0071 seconds\n",
      "time for one step: 0.0082 seconds\n",
      "time for one step: 0.0078 seconds\n",
      "time for one step: 0.0080 seconds\n",
      "time for one step: 0.0077 seconds\n",
      "time for one step: 0.0073 seconds\n",
      "time for one step: 0.0071 seconds\n",
      "time for one step: 0.0076 seconds\n",
      "time for one step: 0.0075 seconds\n",
      "time for one step: 0.0078 seconds\n",
      "time for one step: 0.0075 seconds\n",
      "time for one step: 0.0084 seconds\n",
      "time for one step: 0.0076 seconds\n",
      "time for one step: 0.0072 seconds\n",
      "time for one step: 0.0071 seconds\n",
      "time for one step: 0.0075 seconds\n",
      "time for one step: 0.0072 seconds\n",
      "time for one step: 0.0076 seconds\n",
      "time for one step: 0.0076 seconds\n",
      "time for one step: 0.0079 seconds\n",
      "time for one step: 0.0079 seconds\n",
      "time for one step: 0.0081 seconds\n",
      "time for one step: 0.0074 seconds\n",
      "time for one step: 0.0077 seconds\n",
      "time for one step: 0.0076 seconds\n",
      "time for one step: 0.0076 seconds\n",
      "time for one step: 0.0075 seconds\n",
      "time for one step: 0.0073 seconds\n",
      "time for one step: 0.0077 seconds\n",
      "time for one step: 0.0072 seconds\n",
      "time for one step: 0.0077 seconds\n",
      "time for one step: 0.0078 seconds\n",
      "time for one step: 0.0083 seconds\n",
      "time for one step: 0.0075 seconds\n",
      "time for one step: 0.0076 seconds\n",
      "time for one step: 0.0073 seconds\n",
      "time for one step: 0.0070 seconds\n",
      "time for one step: 0.0072 seconds\n",
      "time for one step: 0.0070 seconds\n",
      "time for one step: 0.0073 seconds\n",
      "time for one step: 0.0071 seconds\n",
      "time for one step: 0.0068 seconds\n",
      "time for one step: 0.0067 seconds\n",
      "time for one step: 0.0067 seconds\n",
      "time for one step: 0.0068 seconds\n",
      "time for one step: 0.0070 seconds\n",
      "time for one step: 0.0073 seconds\n",
      "time for one step: 0.0070 seconds\n",
      "time for one step: 0.0067 seconds\n",
      "time for one step: 0.0077 seconds\n",
      "time for one step: 0.0098 seconds\n",
      "time for one step: 0.0084 seconds\n",
      "time for one step: 0.0081 seconds\n",
      "time for one step: 0.0080 seconds\n",
      "time for one step: 0.0075 seconds\n",
      "time for one step: 0.0081 seconds\n",
      "time for one step: 0.0076 seconds\n",
      "time for one step: 0.0073 seconds\n",
      "time for one step: 0.0076 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-44c28f0ab8f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdsr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdsr_feature_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'FourRoomsMatrix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-c05539983d90>\u001b[0m in \u001b[0;36mdsr_feature_init\u001b[0;34m(ref, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m#         import pdb; pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/LiNCLAB/State representation in RL/DeepRL-master/deep_rl/agent/DSR_agent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m                  \u001b[0;31m# Update all params based on whole loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m                 \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/LiNCLAB/State representation in RL/venv-MPSF/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/LiNCLAB/State representation in RL/venv-MPSF/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dsr = dsr_feature_init(ref=None, game='FourRoomsMatrix', freeze=0, style=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_step_avdsr = 1e5\n",
    "linear_schedule_avdsr = 1e5\n",
    "learning_rate_avdsr = 1e-3 #from 0.05 - 0.001\n",
    "\n",
    "def avdsr_feature_A(**kwargs):\n",
    "    kwargs['tag'] = 'Training avDSR based on DQN agents'\n",
    "    generate_tag(kwargs)\n",
    "    kwargs.setdefault('log_level', 0)\n",
    "    config = Config()\n",
    "    config.merge(kwargs)\n",
    "\n",
    "    config.task_fn = lambda: Task(config.game)\n",
    "    config.eval_env = config.task_fn()\n",
    "    config.c = 1\n",
    "\n",
    "    config.optimizer_fn = lambda params: torch.optim.RMSprop(params, learning_rate_avdsr)\n",
    "#     config.network_fn = lambda: SRNet(config.action_dim, SRIdentityBody(config.state_dim), \\\n",
    "#                                       hidden_units=(), config=0) #CHECK\n",
    "    config.network_fn = lambda: SRNetCNN_MultiChannel(config.action_dim, SRIdentityBody(config.state_dim), \\\n",
    "                                      hidden_units=(2000,), config=config.style) #CHECK\n",
    "    config.replay_fn = lambda: Replay(memory_size=int(3e5), batch_size=10)\n",
    "\n",
    "    config.random_action_prob = LinearSchedule(1, 1, linear_schedule_avdsr) # CHECK\n",
    "    config.discount = 0.99\n",
    "    config.target_network_update_freq = 200\n",
    "    config.exploration_steps = 0\n",
    "    config.double_q = False\n",
    "    config.sgd_update_frequency = 4\n",
    "    config.gradient_clip = 5\n",
    "    config.max_steps = max_step_avdsr\n",
    "    config.async_actor = False\n",
    "    \n",
    "    agent = avDSRAgent(config, config.agents, style='DQN')\n",
    "    #run_steps function below\n",
    "    config = agent.config\n",
    "    agent_name = agent.__class__.__name__\n",
    "    t0 = time.time()\n",
    "    # agent.network = load_agent('avdsr-A')\n",
    "    while True:\n",
    "        if config.log_interval and not agent.total_steps % config.log_interval:\n",
    "            agent.logger.info('steps %d, %.2f steps/s' % (agent.total_steps, config.log_interval / (time.time() - t0)))\n",
    "            t0 = time.time()\n",
    "        if config.max_steps and agent.total_steps >= config.max_steps:\n",
    "#             store_agent(agent.network, 'avdsr-A-'+game)\n",
    "            return agent\n",
    "            break\n",
    "#         import pdb; pdb.set_trace()\n",
    "        agent.step()\n",
    "        agent.switch_task()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-12 20:39:31,278 - root - INFO: steps 0, 349525333.33 steps/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no key\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'network'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1d122c985e7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mavdsr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavdsr_feature_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'FourRoomsMatrix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-0e39d372029d>\u001b[0m in \u001b[0;36mavdsr_feature_A\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#         import pdb; pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/LiNCLAB/State representation in RL/DeepRL-master/deep_rl/agent/avDSR_agent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# Store transitions in the buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# During exploration, the network does not get updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mtransitions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0mexperiences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransitions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/LiNCLAB/State representation in RL/DeepRL-master/deep_rl/agent/BaseAgent.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mtransitions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgd_update_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mtransitions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransitions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/LiNCLAB/State representation in RL/DeepRL-master/deep_rl/agent/avDSR_agent.py\u001b[0m in \u001b[0;36m_transition\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_normalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DQN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_normalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'network'"
     ]
    }
   ],
   "source": [
    "avdsr = avdsr_feature_A(game='FourRoomsMatrix', agents=[None], choice=0, style=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-MPSF",
   "language": "python",
   "name": "venv-mpsf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
