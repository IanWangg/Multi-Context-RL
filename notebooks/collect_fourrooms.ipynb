{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gym.utils import seeding\n",
    "from gym import spaces\n",
    "import gym\n",
    "\n",
    "class ClctFourRooms(gym.Env):\n",
    "    def __init__ (self, num_goals=10, num_types=2, object_priors=[1, 1], reward_vec=None, horizon=200, p=0, config=1, layout='3roomsh', seed=1234, cont=False):\n",
    "        \"\"\"\n",
    "        config -> configouration of the state space\n",
    "            0 - returns tabular index of the state\n",
    "            1 - returns one hot encoded vector of the state\n",
    "            2 - returns matrix form of the state\n",
    "        \"\"\"\n",
    "        if(layout == '4rooms'):\n",
    "            layout = \"\"\"\\\n",
    "wwwwwwwwwwwww\n",
    "w     w     w\n",
    "w     w     w\n",
    "w           w\n",
    "w     w     w\n",
    "w     w     w\n",
    "ww wwww     w\n",
    "w     www www\n",
    "w     w     w\n",
    "w     w     w\n",
    "w           w\n",
    "w     w     w\n",
    "wwwwwwwwwwwww\n",
    "\"\"\"\n",
    "        elif(layout == '3rooms'):\n",
    "            layout = \"\"\"\\\n",
    "wwwwwwwwwwwww\n",
    "w   w   w   w\n",
    "w   w       w\n",
    "w   w   w   w\n",
    "w   w   w   w\n",
    "w   w   w   w\n",
    "w   w   w   w\n",
    "w   w   w   w\n",
    "w   w   w   w\n",
    "w       w   w\n",
    "w   w   w   w\n",
    "w   w   w   w\n",
    "wwwwwwwwwwwww\n",
    "\"\"\"\n",
    "        elif(layout == '3roomsh'):\n",
    "            layout = \"\"\"\\\n",
    "wwwwwwwwwwwww\n",
    "w           w\n",
    "w           w\n",
    "wwwwwwwww www\n",
    "w           w\n",
    "w           w\n",
    "w           w\n",
    "w           w\n",
    "ww wwwwwwwwww\n",
    "w           w\n",
    "w           w\n",
    "w           w\n",
    "wwwwwwwwwwwww\n",
    "\"\"\"\n",
    "        elif(layout == 'maze'):\n",
    "            layout = \"\"\"\\\n",
    "wwwwwwwwwwwww\n",
    "w           w\n",
    "w ww wwwwww w\n",
    "w w       w w\n",
    "w w wwwww w w\n",
    "w w w   w w w\n",
    "w w   w   www\n",
    "w w w   w w w\n",
    "w w wwwww w w\n",
    "w w       w w\n",
    "w ww wwwwww w\n",
    "w           w\n",
    "wwwwwwwwwwwww\n",
    "\"\"\"\n",
    "        elif(layout == 'open'):\n",
    "            layout = \"\"\"\\\n",
    "wwwwwwwwwwwww\n",
    "w           w\n",
    "w           w\n",
    "w           w\n",
    "w           w\n",
    "w           w\n",
    "w           w\n",
    "w           w\n",
    "w           w\n",
    "w           w\n",
    "w           w\n",
    "w           w\n",
    "wwwwwwwwwwwww\n",
    "\"\"\"\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "        assert num_types == len(object_priors)\n",
    "            \n",
    "        self.p = p\n",
    "        self.config = config\n",
    "        self.num_goals = num_goals\n",
    "        self.num_types = num_types\n",
    "        self.horizon = horizon\n",
    "        # object priors is the vector of priors of types of each object (so we have to normalize it first)\n",
    "        self.object_priors = np.array(object_priors) / np.sum(object_priors)\n",
    "        # reward_vec is the reward vector for different type of objects\n",
    "        if reward_vec is None:\n",
    "            self.reward_vec = np.ones(shape=(self.num_types,))\n",
    "        else:\n",
    "            self.reward_vec = reward_vec\n",
    "            \n",
    "        # store the number of updates\n",
    "        self.update = 0\n",
    "        \n",
    "        # if we would like to create another object when one object is collected\n",
    "        self.cont = False\n",
    "        \n",
    "        # fix the random seed for reproducibility\n",
    "        np.random.seed(seed)\n",
    "        self.rng = np.random.RandomState(seed)\n",
    "        \n",
    "        # occupancy of the layout(1 -> walls, 0 -> elsewhere)\n",
    "        self.occupancy = np.array([list(map(lambda c: 1 if c=='w' else 0, line)) for line in layout.splitlines()])\n",
    "        \n",
    "        # action space of the env\n",
    "        # 0: UP\n",
    "        # 1: DOWN\n",
    "        # 2: LEFT\n",
    "        # 3: RIGHT\n",
    "        self.a_space = np.array([0, 1, 2, 3])\n",
    "        self.obs_space = np.zeros(np.sum(self.occupancy == 0))\n",
    "        \n",
    "        # observation space (Not used)\n",
    "        # Setting the observation space based on the config\n",
    "        # The observation space is for the network to know what shape of input it should expect\n",
    "        if(config <= 1):\n",
    "            self.observation_space = spaces.Box(low=np.zeros(np.sum(self.occupancy == 0)), high=np.ones(np.sum(self.occupancy == 0)), dtype=np.uint8)\n",
    "        elif(config == 2):\n",
    "            self.observation_space = spaces.Box(low=np.zeros([4, 169]), high=np.ones([4, 169]), dtype=np.uint8)\n",
    "        \n",
    "        # action space\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "        # direction of actions\n",
    "        self.directions = [np.array((-1,0)), np.array((1,0)), np.array((0,-1)), np.array((0,1))]\n",
    "        \n",
    "        # a dictionary that can convert state index (scalar) to state cell location (2-dimension vector)\n",
    "        self.tostate = {}\n",
    "        statenum = 0\n",
    "        for i in range(13):\n",
    "            for j in range(13):\n",
    "                # first entry is the y index (vertival)\n",
    "                # second entry is the x index (horizontal)\n",
    "                if self.occupancy[i,j] == 0:\n",
    "                    self.tostate[(i,j)] = statenum\n",
    "                    statenum += 1\n",
    "        self.tocell = {v:k for k, v in self.tostate.items()}\n",
    "        \n",
    "        # get a list of all available states\n",
    "        self.area = list(range(self.obs_space.shape[0]))\n",
    "        \n",
    "        self.channels_all = len(self.reward_vec) + 2\n",
    "        \n",
    "        # now we put goals to the env\n",
    "        # self.reset()\n",
    "        \n",
    "    # generate a random location in the environment\n",
    "    def random_pos(self):\n",
    "        # choose an random location based on the area\n",
    "        return np.random.choice(self.area)\n",
    "        \n",
    "    def observation(self):\n",
    "        if self.config == 1:\n",
    "            # return one hot encoded map\n",
    "            temp = np.zeros(len(self.obs_space))\n",
    "            temp[self.agent_pos] = 1\n",
    "            return temp\n",
    "        if self.config == 2:\n",
    "            area = np.zeros([self.channels_all, 13, 13], dtype=np.float32)\n",
    "            # first channel is the wall\n",
    "            area[0, :, :] = self.occupancy\n",
    "            \n",
    "            # second channel is the agent\n",
    "            agent_cell = self.tocell[self.agent_pos]\n",
    "            area[1, agent_cell[0], agent_cell[1]] = 1\n",
    "            \n",
    "            # the following channels are objects\n",
    "            for pos, obj in self.objects.items():\n",
    "                x, y = self.tocell[pos]\n",
    "                area[2:, x, y] = obj\n",
    "                \n",
    "            return area\n",
    "        \n",
    "    def render(self):\n",
    "        area = np.array(self.occupancy) * (-1)\n",
    "        agent_cell = self.tocell[self.agent_pos]\n",
    "        area[agent_cell[0], agent_cell[1]] = 10\n",
    "        for pos, obj in self.objects.items():\n",
    "            x, y = self.tocell[pos]\n",
    "            area[x, y] = obj[0] * 5 + 1\n",
    "            \n",
    "        return area\n",
    "        \n",
    "        \n",
    "    def reset(self):\n",
    "        # clear the update count\n",
    "        self.update = 0\n",
    "        \n",
    "        # first put objects to the env (each object is at different places)\n",
    "        self.objects = {}\n",
    "        for _ in range(self.num_goals):\n",
    "            while True:\n",
    "                new_pos = self.random_pos()\n",
    "                if new_pos not in self.objects:\n",
    "                    self.objects[new_pos] = np.random.multinomial(1, self.object_priors)\n",
    "                    break\n",
    "                    \n",
    "        # Then we put the agent to the env\n",
    "        self.agent_pos = self.random_pos()\n",
    "        # if the agent is put onto an object, re-locate the agent\n",
    "        while self.agent_pos in self.objects:\n",
    "            self.agent_pos = self.random_pos()\n",
    "        \n",
    "        # now we have already put the agent and the objects into the env properly\n",
    "        \n",
    "        return self.observation()\n",
    "    \n",
    "    # step function for scavenger env\n",
    "    def step_scavenger(self, action):\n",
    "        # increase the update count\n",
    "        self.update += 1\n",
    "        \n",
    "        # determine the next position\n",
    "        agent_cell = self.tocell[self.agent_pos]\n",
    "        next_cell = tuple(agent_cell + self.directions[action])\n",
    "        \n",
    "        # check if the next position is legal (not in the wall), if it is legal, make the move\n",
    "        # otherwise, stay still\n",
    "        if not self.occupancy[next_cell]:\n",
    "            self.agent_pos = self.tostate[next_cell]\n",
    "        \n",
    "        # then we see if any object is collected\n",
    "        # if no object is consumed, we will get an zero vector\n",
    "        consumed = self.objects.pop(self.agent_pos, np.zeros(shape=(len(self.reward_vec,))))\n",
    "           \n",
    "        # calculate the reward\n",
    "        reward = np.dot(self.reward_vec, consumed)\n",
    "        \n",
    "        # if this game is continuous (never end until the horizon is reached), then we would need to create another object if one object is collected\n",
    "        if self.cont and reward != 0:\n",
    "            while True:\n",
    "                new_pos = self.random_pos()\n",
    "                if new_pos not in self.objects and new_pos != self.agent_pos:\n",
    "                    self.objects[new_pos] = np.random.multinomial(1, self.object_priors)\n",
    "                    break\n",
    "        \n",
    "        # make sure that the objects is removed\n",
    "        assert self.agent_pos not in self.objects\n",
    "                                    \n",
    "        # then we check if this episode is over\n",
    "        done = False\n",
    "        if (self.update >= self.horizon):\n",
    "            done = True\n",
    "        \n",
    "                                    \n",
    "        # return the observations and the reward\n",
    "        return self.observation(), reward, done, {}\n",
    "    \n",
    "    \n",
    "    # step function for simple env\n",
    "    def step_simple(self, action):\n",
    "        # increase the update count\n",
    "        self.update += 1\n",
    "        \n",
    "        # determine the next position\n",
    "        agent_cell = self.tocell[self.agent_pos]\n",
    "        next_cell = tuple(agent_cell + self.directions[action])\n",
    "        \n",
    "        # check if the next position is legal (not in the wall), if it is legal, make the move\n",
    "        # otherwise, stay still\n",
    "        if not self.occupancy[next_cell]:\n",
    "            self.agent_pos = self.tostate[next_cell]\n",
    "            \n",
    "        # then we see if any object is collected\n",
    "        # if no object is consumed, we will get an zero vector\n",
    "        consumed = self.objects.pop(self.agent_pos, np.zeros(shape=(len(self.reward_vec,))))\n",
    "           \n",
    "        # calculate the reward\n",
    "        reward = np.dot(self.reward_vec, consumed)\n",
    "        \n",
    "        done = False\n",
    "        if reward != 0:\n",
    "            done = True\n",
    "            reward = 0\n",
    "        else:\n",
    "            reward = -1\n",
    "            \n",
    "        return self.observation(), reward, done, {}\n",
    "    \n",
    "    def step(self, action):\n",
    "        return step_simple(self, action)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7ff967833c70>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = ClctFourRooms(config=2, layout='open');\n",
    "env.reset()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(env.render())\n",
    "plt.colorbar()\n",
    "\n",
    "env.step(2)\n",
    "plt.figure()\n",
    "plt.imshow(env.render())\n",
    "plt.colorbar()\n",
    "# show_pos(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "{0: (1, 1), 1: (1, 2), 2: (1, 3), 3: (1, 4), 4: (1, 5), 5: (1, 6), 6: (1, 7), 7: (1, 8), 8: (1, 9), 9: (1, 10), 10: (1, 11), 11: (2, 1), 12: (2, 2), 13: (2, 3), 14: (2, 4), 15: (2, 5), 16: (2, 6), 17: (2, 7), 18: (2, 8), 19: (2, 9), 20: (2, 10), 21: (2, 11), 22: (3, 9), 23: (4, 1), 24: (4, 2), 25: (4, 3), 26: (4, 4), 27: (4, 5), 28: (4, 6), 29: (4, 7), 30: (4, 8), 31: (4, 9), 32: (4, 10), 33: (4, 11), 34: (5, 1), 35: (5, 2), 36: (5, 3), 37: (5, 4), 38: (5, 5), 39: (5, 6), 40: (5, 7), 41: (5, 8), 42: (5, 9), 43: (5, 10), 44: (5, 11), 45: (6, 1), 46: (6, 2), 47: (6, 3), 48: (6, 4), 49: (6, 5), 50: (6, 6), 51: (6, 7), 52: (6, 8), 53: (6, 9), 54: (6, 10), 55: (6, 11), 56: (7, 1), 57: (7, 2), 58: (7, 3), 59: (7, 4), 60: (7, 5), 61: (7, 6), 62: (7, 7), 63: (7, 8), 64: (7, 9), 65: (7, 10), 66: (7, 11), 67: (8, 2), 68: (9, 1), 69: (9, 2), 70: (9, 3), 71: (9, 4), 72: (9, 5), 73: (9, 6), 74: (9, 7), 75: (9, 8), 76: (9, 9), 77: (9, 10), 78: (9, 11), 79: (10, 1), 80: (10, 2), 81: (10, 3), 82: (10, 4), 83: (10, 5), 84: (10, 6), 85: (10, 7), 86: (10, 8), 87: (10, 9), 88: (10, 10), 89: (10, 11), 90: (11, 1), 91: (11, 2), 92: (11, 3), 93: (11, 4), 94: (11, 5), 95: (11, 6), 96: (11, 7), 97: (11, 8), 98: (11, 9), 99: (11, 10), 100: (11, 11)}\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "env = ClctFourRooms(config=2);\n",
    "env.reset()\n",
    "# print(env.observation_space.shape)\n",
    "\n",
    "# int(np.prod(env.observation_space.shape))\n",
    "# print(env.agent_pos)\n",
    "env.agent_pos = 0\n",
    "print(env.tocell[env.agent_pos])\n",
    "print(env.tocell)\n",
    "print(env.observation()[3])\n",
    "print(env.agent_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121, 121, 4]\n"
     ]
    }
   ],
   "source": [
    "arena_size = 121\n",
    "\n",
    "num_channels_all = 4\n",
    "\n",
    "arena_shape = [arena_size] * 2 + [num_channels_all]\n",
    "\n",
    "print(arena_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Added by Surya.\n",
    "    SR fully connected body network.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_dim, body, hidden_units=(), gate=F.relu, config=1):\n",
    "        \"\"\"\n",
    "        config -> type of learning on top of state abstraction\n",
    "            0 - typical SR with weights sharing\n",
    "            1 - learning SR without weights sharing\n",
    "        \"\"\"\n",
    "#         print(type(self))\n",
    "#         print(SRNet)\n",
    "        super(SRNet, self).__init__()\n",
    "        # super(SRNet, self).all(*args, **kwargs)\n",
    "        self.body = body\n",
    "        self.output_dim = output_dim# TODO: check if this is the right way to do it\n",
    "        dims = (body.feature_dim,) + hidden_units + (body.feature_dim * output_dim,)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [layer_init(nn.Linear(dim_in, dim_out)) for dim_in, dim_out in zip(dims[:-1], dims[1:])])\n",
    "        \n",
    "        self.gate = gate\n",
    "        self.feature_dim = body.feature_dim * output_dim\n",
    "        if(config == 0):\n",
    "            self.psi2q = Psi2QNet(output_dim, body.feature_dim)\n",
    "        if(config == 1):\n",
    "            self.psi2q = Psi2QNetFC(output_dim, body.feature_dim)\n",
    "\n",
    "        self.to(Config.DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f'init shape {x.shape}')\n",
    "        phi = self.body(tensor(x)) # shape: b x state_dim\n",
    "        print(f'shape after body process {phi.shape}')\n",
    "        psi = phi\n",
    "        for layer in self.layers[:-1]:\n",
    "            psi = self.gate(layer(psi))\n",
    "            print(f'shape after linear layer process {psi.shape}')\n",
    "        psi = self.layers[-1](psi)\n",
    "        print(f'shape after linear layer process {psi.shape}')\n",
    "        \n",
    "        print(f'debug : {psi.shape}, {psi.size(0)}, {self.output_dim}, {self.body.feature_dim}')\n",
    "        \n",
    "        psi = psi.view(psi.size(0), self.output_dim, self.body.feature_dim) # shape: b x action_dim x state_dim\n",
    "        print(f'shape before psi2q {phi.shape}')\n",
    "        out = self.psi2q(psi)\n",
    "        print(f'shape after psi2q psi2q {phi.shape}')\n",
    "\n",
    "        return phi, psi, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048 (2000,) 169 4\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[101, 1, 13, 13]' is invalid for input of size 101",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f0633730231a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/LiNCLAB/State representation in RL/venv-MPSF/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/LiNCLAB/State representation in RL/DeepRL-master/deep_rl/network/network_heads.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Convert to image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mpsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# Conv layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[101, 1, 13, 13]' is invalid for input of size 101"
     ]
    }
   ],
   "source": [
    "state = np.zeros([13, 13, 4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-MPSF",
   "language": "python",
   "name": "venv-mpsf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
